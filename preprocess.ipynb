{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import random\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# First attempt it with one file\n",
    "file1 = \"./data/hw_dataset/parkinson/P_02100002.txt\"\n",
    "control = \"./data/hw_dataset/control/C_000\"\n",
    "file2 = \"./data/new_dataset/parkinson\"\n",
    "new_data = \"G:/My Drive/Sys Lab/modified_data\"\n",
    "x0, y0 = 200.0, 204.0\n",
    "xmin, xmax = 32.0, 401.25\n",
    "\n",
    "parkinsons_1= \"./data/hw_dataset/parkinson/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subset(X, y, filename):\n",
    "    subset = [] # format ([Xi, X2. . . Xf], [yi, y2, . . . yf])\n",
    "    X_temp, y_temp = [], []\n",
    "    for i in tqdm(range(len(X)-50)): # was len(X)\n",
    "        # X_temp.append(X[i])\n",
    "        # y_temp.append(y[i])\n",
    "        if i<=50:\n",
    "            continue\n",
    "        combined_array = np.column_stack((X[i:i+50], y[i:i+50]))\n",
    "        angle = random.randint(1, 360)\n",
    "        theta = np.radians(angle)  # Convert the angle to radians\n",
    "        rotation_matrix = np.array([[np.cos(theta), -np.sin(theta)], \n",
    "                                    [np.sin(theta), np.cos(theta)]])\n",
    "        rotated = np.dot(combined_array, rotation_matrix)\n",
    "        shape = 50\n",
    "        print(rotated[:-1])\n",
    "        print()\n",
    "        print(rotated[-1])\n",
    "        print()\n",
    "        input()\n",
    "        subset.append((filename, i, angle, rotated[:-1], rotated[-1], shape))\n",
    "    print(subset)\n",
    "\n",
    "    return subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_data(filename, label=\"name\"): \n",
    "    with open(filename) as source:\n",
    "        reader = csv.reader(source, delimiter=';')\n",
    "        x = []\n",
    "        # X ; Y; Z; Pressure; GripAngle; Timestamp; Test ID\n",
    "        # 9 second intervals --> \n",
    "        # 0: Static Spiral Test ( Draw on the given spiral pattern)\n",
    "        # 1: Dynamic Spiral Test ( Spiral pattern will blink in a certain time, so subjects need to continue on their draw)\n",
    "        # 2: Circular Motion Test (Subjectd draw circles around the red point)\n",
    "        for line in reader:\n",
    "            x.append(line)\n",
    "        df = np.array(x)\n",
    "        df = df.astype(float)\n",
    "        cond1 = (np.array([df[:, 2]])).T\n",
    "        \n",
    "        # Split based on Test \n",
    "        cond = (np.array([df[:, -1]])).T\n",
    "        df_stat = df[cond[:,0]==0]\n",
    "        df_dyn = df[cond[:,0]==1]\n",
    "        df_circ = df[cond[:,0]==2]\n",
    "\n",
    "        \n",
    "        X, y, z, c, t = df_stat[:,0], df_stat[:,1], df_stat[:,2], df_stat[:, 3], df_stat[:, 4]\n",
    "        print(t.size)\n",
    "        \n",
    "        X = X * (xmax-xmin)/(X.max()-X.min())\n",
    "        X = X- (X[0]-x0)\n",
    "        y = y- (y[0]-y0)\n",
    "        c = (c-c.min())/(c.max()-c.min())\n",
    "        c= c.astype(str)\n",
    "        \n",
    "        \n",
    "        #plt.scatter(X, y, c=c, cmap='viridis')\n",
    "        get_subset(X, y, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_subsets(filepath):\n",
    "    with open(filepath, 'rb') as f:\n",
    "        classification_dict = pkl.load(f)\n",
    "        print(classification_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 4/25 [00:00<00:00, 31.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "983\n",
      "2645\n",
      "1704\n",
      "5278\n",
      "4136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 8/25 [00:00<00:00, 19.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6682\n",
      "4744\n",
      "4577\n",
      "2406\n",
      "1810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 15/25 [00:00<00:00, 21.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "872\n",
      "2716\n",
      "2868\n",
      "4083\n",
      "3240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 22/25 [00:00<00:00, 25.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2884\n",
      "746\n",
      "3620\n",
      "2366\n",
      "2019\n",
      "3080\n",
      "3073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:01<00:00, 20.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9390\n",
      "2327\n",
      "2824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/37 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 6/37 [00:00<00:01, 28.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2378\n",
      "2471\n",
      "1888\n",
      "4973\n",
      "1357\n",
      "2315\n",
      "1426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 16/37 [00:00<00:00, 38.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4174\n",
      "1310\n",
      "1711\n",
      "3088\n",
      "1107\n",
      "4548\n",
      "3620\n",
      "1246\n",
      "1952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 20/37 [00:00<00:00, 36.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6224\n",
      "1382\n",
      "2211\n",
      "12045\n",
      "1325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 28/37 [00:00<00:00, 30.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1816\n",
      "1165\n",
      "1720\n",
      "1279\n",
      "1866\n",
      "526\n",
      "1903\n",
      "1927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37/37 [00:01<00:00, 31.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "841\n",
      "1018\n",
      "575\n",
      "1570\n",
      "2072\n",
      "1810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import random\n",
    "\n",
    "import os\n",
    "\n",
    "# First attempt it with one file\n",
    "file1 = \"./data/hw_dataset/parkinson/P_02100002.txt\"\n",
    "control = \"./data/hw_dataset/control/C_000\"\n",
    "file2 = \"./data/new_dataset/parkinson\"\n",
    "new_data = \"G:/My Drive/Sys Lab/modified_data/new\"\n",
    "x0, y0 = 200.0, 204.0\n",
    "xmin, xmax = 32.0, 401.25\n",
    "\n",
    "parkinsons_1= \"./data/hw_dataset/parkinson/\"\n",
    "subset = []\n",
    "df_all = {\"X\":[], \"y\":[], \"filename\":[]}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def read_data(filename, label=\"name\"): \n",
    "    with open(filename) as source:\n",
    "        reader = csv.reader(source, delimiter=';')\n",
    "        x = []\n",
    "        # X ; Y; Z; Pressure; GripAngle; Timestamp; Test ID\n",
    "        # 9 second intervals --> \n",
    "        # 0: Static Spiral Test ( Draw on the given spiral pattern)\n",
    "        # 1: Dynamic Spiral Test ( Spiral pattern will blink in a certain time, so subjects need to continue on their draw)\n",
    "        # 2: Circular Motion Test (Subjectd draw circles around the red point)\n",
    "        for line in reader:\n",
    "            x.append(line)\n",
    "        df = np.array(x)\n",
    "        df = df.astype(float)\n",
    "        cond1 = (np.array([df[:, 2]])).T\n",
    "        \n",
    "        # Split based on Test \n",
    "        cond = (np.array([df[:, -1]])).T\n",
    "        df_stat = df[cond[:,0]==0]\n",
    "        df_dyn = df[cond[:,0]==1]\n",
    "        df_circ = df[cond[:,0]==2]\n",
    "        \n",
    "        if len(df_stat):\n",
    "            \n",
    "            X, y, z, c, t = df_stat[:,0], df_stat[:,1], df_stat[:,2], df_stat[:, 3], df_stat[:, 4]\n",
    "            print(t.size)\n",
    "            \n",
    "            X = X * (xmax-xmin)/(X.max()-X.min())\n",
    "            X = X- (X[0]-x0)\n",
    "            y = y- (y[0]-y0)\n",
    "            c = (c-c.min())/(c.max()-c.min())\n",
    "            c= c.astype(str)\n",
    "        \n",
    "            \n",
    "            #plt.scatter(X, y, c=c, cmap='viridis')\n",
    "            df_all[\"X\"].append(X)\n",
    "            df_all[\"y\"].append(y)\n",
    "            df_all[\"filename\"].append(filename)\n",
    "        \n",
    "\n",
    "def visualize_subsets(filepath):\n",
    "    with open(filepath, 'rb') as f:\n",
    "        classification_dict = pkl.load(f)\n",
    "        print(classification_dict)\n",
    "\n",
    "#visualize_subsets(f\"{new_data}/dummy.pkl\")\n",
    "\n",
    "parkinsons_1 = \"data/hw_dataset/parkinson\"\n",
    "parkinsons_2 = \"data/new_dataset/parkinson\"\n",
    "\n",
    "ls = os.listdir(parkinsons_1)\n",
    "\n",
    "for i in tqdm(ls):\n",
    "    read_data(f\"./{parkinsons_1}/{i}\", label=\"Parkinson's\")\n",
    "\n",
    "ls2 = os.listdir(parkinsons_2)   \n",
    "for i in tqdm(ls2):\n",
    "    read_data(f\"./{parkinsons_2}/{i}\", label=\"Parkinson's\")\n",
    "\n",
    "df = pd.DataFrame(df_all)\n",
    "df.to_pickle(\"data/data_original_spiral.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[200.0, 200.0, 200.0, 200.0, 201.0519943019943...</td>\n",
       "      <td>[204.0, 204.0, 204.0, 204.0, 204.0, 204.0, 204...</td>\n",
       "      <td>./data/hw_dataset/parkinson/P_02100001.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[200.0, 200.0, 200.95413436692508, 200.9541343...</td>\n",
       "      <td>[204.0, 203.0, 202.0, 202.0, 202.0, 201.0, 201...</td>\n",
       "      <td>./data/hw_dataset/parkinson/P_02100002.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[200.0, 201.9693333333333, 202.95399999999998,...</td>\n",
       "      <td>[204.0, 202.0, 200.0, 203.0, 203.0, 202.0, 202...</td>\n",
       "      <td>./data/hw_dataset/parkinson/P_05060003.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200...</td>\n",
       "      <td>[204.0, 204.0, 204.0, 204.0, 204.0, 204.0, 203...</td>\n",
       "      <td>./data/hw_dataset/parkinson/P_05060004.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200...</td>\n",
       "      <td>[204.0, 204.0, 204.0, 204.0, 204.0, 204.0, 205...</td>\n",
       "      <td>./data/hw_dataset/parkinson/P_09100001.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>[200.0, 200.0, 200.0, 200.0, 200.0, 199.017952...</td>\n",
       "      <td>[204.0, 204.0, 204.0, 204.0, 204.0, 204.0, 203...</td>\n",
       "      <td>./data/new_dataset/parkinson/H_P000-0039.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>[200.0, 200.0, 199.02314814814815, 199.0231481...</td>\n",
       "      <td>[204.0, 203.0, 203.0, 202.0, 202.0, 202.0, 203...</td>\n",
       "      <td>./data/new_dataset/parkinson/H_P000-0040.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>[200.0, 199.00202702702703, 199.00202702702703...</td>\n",
       "      <td>[204.0, 205.0, 206.0, 206.0, 207.0, 207.0, 207...</td>\n",
       "      <td>./data/new_dataset/parkinson/H_p000-0041.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>[200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200...</td>\n",
       "      <td>[204.0, 204.0, 203.0, 203.0, 203.0, 203.0, 203...</td>\n",
       "      <td>./data/new_dataset/parkinson/H_p000-0042.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>[200.0, 200.0, 200.0, 200.0, 199.0359007832898...</td>\n",
       "      <td>[204.0, 204.0, 203.0, 203.0, 202.0, 201.0, 201...</td>\n",
       "      <td>./data/new_dataset/parkinson/H_p000-0043.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    X  \\\n",
       "0   [200.0, 200.0, 200.0, 200.0, 201.0519943019943...   \n",
       "1   [200.0, 200.0, 200.95413436692508, 200.9541343...   \n",
       "2   [200.0, 201.9693333333333, 202.95399999999998,...   \n",
       "3   [200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200...   \n",
       "4   [200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200...   \n",
       "..                                                ...   \n",
       "56  [200.0, 200.0, 200.0, 200.0, 200.0, 199.017952...   \n",
       "57  [200.0, 200.0, 199.02314814814815, 199.0231481...   \n",
       "58  [200.0, 199.00202702702703, 199.00202702702703...   \n",
       "59  [200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200...   \n",
       "60  [200.0, 200.0, 200.0, 200.0, 199.0359007832898...   \n",
       "\n",
       "                                                    y  \\\n",
       "0   [204.0, 204.0, 204.0, 204.0, 204.0, 204.0, 204...   \n",
       "1   [204.0, 203.0, 202.0, 202.0, 202.0, 201.0, 201...   \n",
       "2   [204.0, 202.0, 200.0, 203.0, 203.0, 202.0, 202...   \n",
       "3   [204.0, 204.0, 204.0, 204.0, 204.0, 204.0, 203...   \n",
       "4   [204.0, 204.0, 204.0, 204.0, 204.0, 204.0, 205...   \n",
       "..                                                ...   \n",
       "56  [204.0, 204.0, 204.0, 204.0, 204.0, 204.0, 203...   \n",
       "57  [204.0, 203.0, 203.0, 202.0, 202.0, 202.0, 203...   \n",
       "58  [204.0, 205.0, 206.0, 206.0, 207.0, 207.0, 207...   \n",
       "59  [204.0, 204.0, 203.0, 203.0, 203.0, 203.0, 203...   \n",
       "60  [204.0, 204.0, 203.0, 203.0, 202.0, 201.0, 201...   \n",
       "\n",
       "                                        filename  \n",
       "0     ./data/hw_dataset/parkinson/P_02100001.txt  \n",
       "1     ./data/hw_dataset/parkinson/P_02100002.txt  \n",
       "2     ./data/hw_dataset/parkinson/P_05060003.txt  \n",
       "3     ./data/hw_dataset/parkinson/P_05060004.txt  \n",
       "4     ./data/hw_dataset/parkinson/P_09100001.txt  \n",
       "..                                           ...  \n",
       "56  ./data/new_dataset/parkinson/H_P000-0039.txt  \n",
       "57  ./data/new_dataset/parkinson/H_P000-0040.txt  \n",
       "58  ./data/new_dataset/parkinson/H_p000-0041.txt  \n",
       "59  ./data/new_dataset/parkinson/H_p000-0042.txt  \n",
       "60  ./data/new_dataset/parkinson/H_p000-0043.txt  \n",
       "\n",
       "[61 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the Location in Human data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import random\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified  = \"./data/modified_all.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    print(index, row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
